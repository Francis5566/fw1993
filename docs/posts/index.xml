<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Categories | goatwu1993</title>
    <link>https://goatwu1993.github.io/blog/posts/</link>
      <atom:link href="https://goatwu1993.github.io/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    <description>Categories</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 22 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Categories</title>
      <link>https://goatwu1993.github.io/blog/posts/</link>
    </image>
    
    <item>
      <title>Apache Kafka - hands-on (1 broker)</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-3/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-3/</guid>
      <description>&lt;h2 id=&#34;install-kafka&#34;&gt;Install Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檔案位置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/usr/local/etc/kafka&lt;/li&gt;
&lt;li&gt;/usr/local/Cellar/kafka/$版號&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /usr/local/Cellar/kafka/*
# 啟動zookeeper
./bin/zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties
# 啟動kafka
./bin/kafka-server-start /usr/local/etc/kafka/server.properties
# 建一個名為 test-kafka 的 Topic
./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test-kafka

# 查看目前已經建立過的 Topic
./bin/kafka-topics --list --zookeeper localhost:2181\n\n
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper--kafka&#34;&gt;啟動 zookeeper &amp;amp; kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
brew services start kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api-選擇&#34;&gt;Consumer &amp;amp; Producer API 選擇&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;p&gt;console1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;console2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到 console1 的輸入&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - hands-on (3 brokers)</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-4/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-4/</guid>
      <description>&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper&#34;&gt;啟動 zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟三個-brokers&#34;&gt;開啟三個 Brokers&lt;/h2&gt;
&lt;p&gt;分别修改 server1.properties、server2.properties&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;修改位置&lt;/th&gt;
&lt;th&gt;server.properties&lt;/th&gt;
&lt;th&gt;server1.properties&lt;/th&gt;
&lt;th&gt;server2.properties&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;broker.id&lt;/td&gt;
&lt;td&gt;broker.id=0&lt;/td&gt;
&lt;td&gt;broker.id=1&lt;/td&gt;
&lt;td&gt;broker.id=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;listeners&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9092&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9093&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;log.dir&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-0&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-1&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-server-start /usr/local/etc/kafka/server.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server1.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server2.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟一個兩個副本的-topic&#34;&gt;開啟一個兩個副本的 Topic&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic mytopic
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api-選擇&#34;&gt;Consumer &amp;amp; Producer API 選擇&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;1-shell-script&#34;&gt;1. Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - Part1</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-p1/</link>
      <pubDate>Thu, 09 Jan 2020 19:53:34 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-p1/</guid>
      <description>&lt;h2 id=&#34;what-is-kafka&#34;&gt;What is Kafka&lt;/h2&gt;
&lt;p&gt;Kafka 是一個分散式的訊息處理平台(message/stream processing platform)，仲介處理端到端的實時訊息傳輸。&lt;/p&gt;
&lt;h2 id=&#34;kafka-特點&#34;&gt;Kafka 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;分散式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供 pub-sub 及 point-to-point 兩種 queue mode&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用優化過的 binary TCP-based protocol，多條訊息會先寫入記憶體緩衝中存成 Batch 一同傳輸，減少網路封包的 Overhead&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對資料的包裝&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輕量級&lt;/li&gt;
&lt;li&gt;可壓縮&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;避免物件包覆，直接以檔案的型式來處理資料&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 OS 的 page cache，不需要額外 Applicaion Cache ，爭取珍貴的記憶體空間&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-優點&#34;&gt;Kafka 優點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reliability 可靠&lt;/li&gt;
&lt;li&gt;Scalability 可擴展&lt;/li&gt;
&lt;li&gt;Durability 耐用性&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;li&gt;Fault Tolerance 容錯機制&lt;/li&gt;
&lt;li&gt;Zero downtime&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;詳細原因要先了解 Kafka 架構&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - Part2</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-2/</link>
      <pubDate>Thu, 09 Jan 2020 19:53:34 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-2/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;This is an image&#34;&gt;
Picture from wiki&lt;/p&gt;
&lt;h2 id=&#34;producers&#34;&gt;Producers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;負責將訊息 push 到 Brokers，訊息需要指定 Topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;實作 Kafka 提供的 Producer API&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumers&#34;&gt;Consumers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在訂閱 Topics 之後，從 Brokers pull 訊息&lt;/li&gt;
&lt;li&gt;實作 Kafka 提供的 Consumer API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumer-group&#34;&gt;Consumer Group&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;每個 Consumer 屬於一個特定的 Consumer Group&lt;/li&gt;
&lt;li&gt;訊息可以發送到多個不同的 Consumer Group，但只會有一個 Consumer 消化該訊息&lt;/li&gt;
&lt;li&gt;Consumer Group 裡面每個 Consumer 對應到一個 partition，因此 Consumer 數目小於 partition 數目。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brokers&#34;&gt;Brokers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的節點叫做 Broker&lt;/li&gt;
&lt;li&gt;仲介處理 Consumer 以及 Producers 的訊息
&lt;ul&gt;
&lt;li&gt;發送訊息需要指定 Topic&lt;/li&gt;
&lt;li&gt;Topic 被分為多個 Partition&lt;/li&gt;
&lt;li&gt;Partition 會有多個 Replica&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;broker-controller&#34;&gt;Broker controller&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;其中一個 Broker 會被推選為 Controller&lt;/li&gt;
&lt;li&gt;負責偵測 Broker 級別的 Failure，幫忙所有受影響的 Partition 更換 Partition Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的訊息為鍵值對，使用鍵值對的雲音是可以提供 Key 並快速查詢訊息在哪個 Partition。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topics&#34;&gt;Topics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;topics-定義&#34;&gt;Topics 定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Topics 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 發送訊息時，會指定一至多個 Topics&lt;/li&gt;
&lt;li&gt;Consumers 訂閱一或多個 Topics&lt;/li&gt;
&lt;li&gt;一個 Topic 切成 1~n 個 Partitions，稱為 replication-factor&lt;/li&gt;
&lt;li&gt;Topics 分為 Regular Topics 及 Compacted topics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;regular-topics&#34;&gt;Regular Topics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;設定 retention time，超過則 Kafka 可刪除資料以釋出硬碟空間&lt;/li&gt;
&lt;li&gt;Default 留存時間為 7 天&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;compacted-topics&#34;&gt;Compacted Topics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;沒有有效期限&lt;/li&gt;
&lt;li&gt;若 Key 重複，新訊息會覆蓋舊的訊息&lt;/li&gt;
&lt;li&gt;Producer 可發送值為 null 的鍵值對以永久刪除該資料，稱作 tombstone message&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partitions&#34;&gt;Partitions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;partitions-定義&#34;&gt;Partitions 定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partition 是 Queue 概念的實作，訊息根據 offset 嚴格排序&lt;/li&gt;
&lt;li&gt;Partition 物理上是磁碟的連續區域，新訊息會被 append 到 partition 尾端，以確保高效率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-offset&#34;&gt;Partition offset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Message 在 partition 裡面會有唯一的 index，稱作 offset&lt;/li&gt;
&lt;li&gt;Offset 為 Long 型態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;replica-副本&#34;&gt;Replica 副本&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partition 產生 n 個副本，分散至各個 Broker 上，n 稱作 replication-factor&lt;/li&gt;
&lt;li&gt;只要各個 Partition 至少一個在線，則服務不會中斷&lt;/li&gt;
&lt;li&gt;常常使用 2 ~ 3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-leader&#34;&gt;Partition Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Broker Controller 對每個 Partition 指定一個 Leader&lt;/li&gt;
&lt;li&gt;Partition Leader 負責接收資料，接收並寫入後，將資料 replicate 到全部 replica/partition follower&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-follower&#34;&gt;Partition Follower&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同一 Partition 的 non-leader replica&lt;/li&gt;
&lt;li&gt;概念上為只追隨某個 partition 的 Consumer，只 subscribe partition Leader，發現更新時 pull 到本地端&lt;/li&gt;
&lt;li&gt;當 Partition Leader 失效，Broker Controller 從 ISR 中選出新 Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;isr&#34;&gt;ISR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當 Leader 收到訊息時，所有 Follower 都需要寫入，已經更新至和 Leader 同步的 Followers 稱為 ISRs(in-sync replica)&lt;/li&gt;
&lt;li&gt;Record 只有在全部的 ISR 都同步時，才被視為成功 Commited&lt;/li&gt;
&lt;li&gt;Consumer 只能從已經 Commit 成功的 Record 讀取紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-cluster&#34;&gt;Kafka Cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;n 個 Broker 組成 Cluster&lt;/li&gt;
&lt;li&gt;可以 zero downtime 擴展&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;管理叢集配置&lt;/li&gt;
&lt;li&gt;負責管理及協調 Broker&lt;/li&gt;
&lt;li&gt;通知 Producer 及 Consumer
&lt;ul&gt;
&lt;li&gt;新的 Broker 出現&lt;/li&gt;
&lt;li&gt;Broker failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當 Zookeeper 發出通知，Consumer 及 Producer 根據通知決定要使用哪一個 Broker&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zookeeper.apache.org/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-簡易入門-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/readme/</guid>
      <description>&lt;h1 id=&#34;welcome-to-blog_kafka-&#34;&gt;Welcome to blog_kafka 👋&lt;/h1&gt;
&lt;h2 id=&#34;author&#34;&gt;Author&lt;/h2&gt;
&lt;p&gt;👤 &lt;strong&gt;goatwu1993&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;show-your-support&#34;&gt;Show your support&lt;/h2&gt;
&lt;p&gt;Give a ⭐️ if this project helped you!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This README was generated with ❤️ by 
&lt;a href=&#34;https://github.com/kefranabg/readme-md-generator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;readme-md-generator&lt;/a&gt;
&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
