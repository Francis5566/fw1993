<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bigdata | goatwu1993</title>
    <link>https://goatwu1993.github.io/blog/tags/bigdata/</link>
      <atom:link href="https://goatwu1993.github.io/blog/tags/bigdata/index.xml" rel="self" type="application/rss+xml" />
    <description>bigdata</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 27 Feb 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>bigdata</title>
      <link>https://goatwu1993.github.io/blog/tags/bigdata/</link>
    </image>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;what-is-hive&#34;&gt;What is Hive&lt;/h2&gt;
&lt;p&gt;Apache Hive 是基於 Hadoop 的 Data warehouse 軟體，最初由 Facebook 開發，當資料集很大，Hive 提供一個類似 SQL 的語言以用來讀/寫/管理大量或分散式的數據集&lt;/p&gt;
&lt;h2 id=&#34;what-can-hive-do&#34;&gt;What can hive do&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可用 SQL 存取數據的工具，因此可以用來做一些 Datawarehousing 常用到的工作，例如 ETL, Reporting 和資料分析&lt;/li&gt;
&lt;li&gt;Hive 被用來 query 和管理分散式數 Hadoop，可以是 Apache HDFS 或是 Apache HBase&lt;/li&gt;
&lt;li&gt;透過 Apache Tez, Apache Spark 或 MapReduce 進行 Query execution&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.edureka.co/blog/hive-commands-with-examples&#34;&gt;https://www.edureka.co/blog/hive-commands-with-examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HIVE&#34;&gt;https://cwiki.apache.org/confluence/display/HIVE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;環境配置&#34;&gt;環境配置&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Java
&lt;ul&gt;
&lt;li&gt;JDK&lt;/li&gt;
&lt;li&gt;設置 PATH 和 JAVA_HOME 變量，添加以下命令到〜/.bashrc 文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hadoop&lt;/li&gt;
&lt;li&gt;HDFS&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&#34;&gt;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hiveql_select_where.html&#34;&gt;http://tw.gitbook.net/hive/hiveql_select_where.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;hive-數據類型&#34;&gt;Hive 數據類型&lt;/h2&gt;
&lt;p&gt;本章介紹 Hive 不同的數據類型，用於創建表。Hive 所有數據類型分為四種類型，給出如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Numeric Types&lt;/li&gt;
&lt;li&gt;Date/Time Types&lt;/li&gt;
&lt;li&gt;String Types&lt;/li&gt;
&lt;li&gt;Misc Types&lt;/li&gt;
&lt;li&gt;Complex Types&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&#34;&gt;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hive_data_types.html&#34;&gt;http://tw.gitbook.net/hive/hive_data_types.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;what-is-hiveql&#34;&gt;What is HiveQL&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hive&amp;gt;create schema if not exists test;

hive&amp;gt;create external table if not exists test.test_data (row1 int, row2 int, row3 decimal(10,3), row4 int) row format delimited fields terminated by &#39;,&#39; stored as textfile location &#39;hdfs://172.18.1.1:9000/user/hadoop/test/&#39;;

hive&amp;gt;select * from test.test_data where row3 &amp;gt; 2.499;
SELECT * FROM test.test_data WHERE row3 &amp;gt; 2.499;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&#34;&gt;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hiveql_select_where.html&#34;&gt;http://tw.gitbook.net/hive/hiveql_select_where.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>pyspark install</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/pyspark-p1-pyspark-install/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/pyspark-p1-pyspark-install/</guid>
      <description>&lt;h2 id=&#34;pyspark&#34;&gt;pyspark&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;apt-get install python3
pip3 install pyspark
pip3 install py4j
pip3 install findspark
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://opensource.com/article/18/11/pyspark-jupyter-notebook&#34;&gt;https://opensource.com/article/18/11/pyspark-jupyter-notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka mechanism</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;producer&#34;&gt;Producer&lt;/h2&gt;
&lt;h3 id=&#34;producer-連接&#34;&gt;Producer 連接&lt;/h3&gt;
&lt;h3 id=&#34;producer-發送訊息時&#34;&gt;Producer 發送訊息時&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper / bootstrap server&lt;/li&gt;
&lt;li&gt;Topics&lt;/li&gt;
&lt;li&gt;Key(可為 Null)&lt;/li&gt;
&lt;li&gt;Value(可為 Null)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Topic 被分為多個 Partition&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition 會有多個 Replica&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Broker controller&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中一個 Broker 會被推選為 Controller&lt;/li&gt;
&lt;li&gt;負責偵測 Broker 級別的 Failure，幫忙所有受影響的 Partition 更換 Partition Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的訊息為鍵值對，使用鍵值對可以提供 Key -&amp;gt; Partition -&amp;gt; Offset 的查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 發送訊息時，會指定一至多個 Topics。Consumers 訂閱一或多個 Topics&lt;/li&gt;
&lt;li&gt;Topics 分為 Regular Topics 及 Compacted topics&lt;/li&gt;
&lt;li&gt;Regular Topics 需要設定 retention time，超過則 Kafka 可刪除資料以釋出硬碟空間&lt;/li&gt;
&lt;li&gt;Compacted Topics 則訊息沒有有效期限，唯若 Key 重複，新訊息會覆蓋舊的訊息。Producer 可發送值為 null 的鍵值對以永久刪除該資料，稱作 tombstone message&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;建立 Topic 時需要指定 Partitions 數目，之後只能增加不能減少&lt;/li&gt;
&lt;li&gt;Partition 是 Queue，訊息按 offset 嚴格排序，新訊息被 append 至尾端&lt;/li&gt;
&lt;li&gt;由於是磁碟的連續區域，因此效率很高&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-offset&#34;&gt;Partition offset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;訊息在 partition 裡面的 index，稱作 offset，為 Long 型態的整數&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Partition 產生 n 個副本，分散至各個 Broker 上，n 稱作 replication-factor&lt;/li&gt;
&lt;li&gt;成功同步的 Replica 稱作 
&lt;a href=&#34;#ISR&#34;&gt;ISR&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-leader&#34;&gt;Partition Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Broker Controller 對每個 Partition 指定一個 Leader&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition Leader 負責接收資料，接收並寫入後，將資料 replicate 到全部 replica/partition follower&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-follower&#34;&gt;Partition Follower&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同一 Partition 的 non-leader replica&lt;/li&gt;
&lt;li&gt;概念上為只追隨某個 partition 的 Consumer，只 subscribe partition Leader，發現更新時 pull 到本地端&lt;/li&gt;
&lt;li&gt;當 Partition Leader 失效，Broker Controller 從 ISR 中選出新 Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;isr&#34;&gt;ISR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當 Leader 收到訊息時，所有 Follower 都需要寫入，已經更新至和 Leader 同步的 Followers 稱為 ISRs(in-sync replica)&lt;/li&gt;
&lt;li&gt;Record 只有在全部的 ISR 都同步時，才被視為成功 Commited&lt;/li&gt;
&lt;li&gt;Consumer 只能從已經 Commit 成功的 Record 讀取紀錄&lt;/li&gt;
&lt;li&gt;對於一個 Topic，只要各個 Partition 皆有一個 ISR 在線，則內容保持一致且服務不中斷&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-cluster&#34;&gt;Kafka Cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;n 個 Broker 組成 Cluster&lt;/li&gt;
&lt;li&gt;可以 zero downtime 擴展&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;管理叢集配置&lt;/li&gt;
&lt;li&gt;負責管理及協調 Broker&lt;/li&gt;
&lt;li&gt;通知 Producer 及 Consumer
&lt;ul&gt;
&lt;li&gt;新的 Broker 出現&lt;/li&gt;
&lt;li&gt;Broker failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當 Zookeeper 發出通知，Consumer 及 Producer 根據通知決定要使用哪一個 Broker&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zookeeper.apache.org/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-簡易入門-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with multi brokers</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</guid>
      <description>&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper&#34;&gt;啟動 zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟三個-brokers&#34;&gt;開啟三個 Brokers&lt;/h2&gt;
&lt;p&gt;分别修改 server1.properties, server2.properties&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;修改位置&lt;/th&gt;
&lt;th&gt;server.properties&lt;/th&gt;
&lt;th&gt;server1.properties&lt;/th&gt;
&lt;th&gt;server2.properties&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;broker.id&lt;/td&gt;
&lt;td&gt;broker.id=0&lt;/td&gt;
&lt;td&gt;broker.id=1&lt;/td&gt;
&lt;td&gt;broker.id=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;listeners&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9092&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9093&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;log.dir&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-0&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-1&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-server-start /usr/local/etc/kafka/server.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server1.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server2.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟一個兩個副本的-topic&#34;&gt;開啟一個兩個副本的 Topic&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic mytopic
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api&#34;&gt;Consumer &amp;amp; Producer API&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到訊息傳送過去&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with single broker</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</guid>
      <description>&lt;h2 id=&#34;install-kafka&#34;&gt;Install Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檔案位置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/usr/local/etc/kafka&lt;/li&gt;
&lt;li&gt;/usr/local/Cellar/kafka/$版號&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /usr/local/Cellar/kafka/*
# 啟動zookeeper
./bin/zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties
# 啟動kafka
./bin/kafka-server-start /usr/local/etc/kafka/server.properties
# 建一個名為 test-kafka 的 Topic
./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test-kafka

# 查看目前已經建立過的 Topic
./bin/kafka-topics --list --zookeeper localhost:2181\n\n
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper--kafka&#34;&gt;啟動 zookeeper &amp;amp; kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
brew services start kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api-選擇&#34;&gt;Consumer &amp;amp; Producer API 選擇&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;p&gt;console1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;console2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到 console1 的輸入&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Some of Kafka terminology</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;producers&#34;&gt;Producers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;負責將訊息 push 到 Kafka cluster，任何實作 Producer API 的 Client&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumers&#34;&gt;Consumers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;從 Kafka cluster pull 訊息，任何實作 Consumer API 的 Client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer group&lt;/strong&gt;: 多個 Consumer 可組成 Consumer group&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brokers&#34;&gt;Brokers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Broker&lt;/strong&gt;: Kafka 的單一節點稱作 Broker&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Cluster&lt;/strong&gt;: 多個 broker 組成 Kafka Cluster&lt;/li&gt;
&lt;li&gt;Broker 可以說是 Apache Kafka 的 Server 端，仲介處理 Client(Consumer 以及 Producer)的訊息&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的訊息為鍵值對，提供 Topic + Key 對 Partition 的查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 發送訊息時指定 Topic&lt;/li&gt;
&lt;li&gt;Consumers 訂閱 Topic&lt;/li&gt;
&lt;li&gt;Topic 被分為多個 Partition&lt;/li&gt;
&lt;li&gt;Partition 會有多個 Replica&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;建立 Topic 時需要指定 Partitions 數目，Topic 會被分為多個 Partition，Partition 數目之後只能增加不能減少&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Partition offset&lt;/strong&gt;: 訊息在 partition 裡面的 index，稱作 offset，為 Long 型態的整數&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;replication-factor&lt;/strong&gt;: Partition 產生 n 個副本，分散至各個 Broker 上&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISR&lt;/strong&gt;: 成功同步的 Replica 稱作 ISR&lt;/li&gt;
&lt;li&gt;Replica 用於保證分散式系統的高可用&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apache 的另一個分散式專案，可管理系統配置&lt;/li&gt;
&lt;li&gt;負責 Kafka 的以下功能
&lt;ul&gt;
&lt;li&gt;儲存 metadata&lt;/li&gt;
&lt;li&gt;選舉 controller/leader&lt;/li&gt;
&lt;li&gt;Consumer group 發生變化時，進行 rebalance&lt;/li&gt;
&lt;li&gt;當 Producer 指定 ZK(而非 bootstrap server)，ZK 負責返回 broker list&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kafka Improvement Proposals 已經通過，將 Zookeeper 從 Kafka 移除，使用 bootstrap server/broker controller/共識來維護 Kafka ，&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-簡易入門-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&#34;&gt;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p1-whatishadoop/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p1-whatishadoop/</guid>
      <description>&lt;h2 id=&#34;what-is-hadoop&#34;&gt;What is Hadoop&lt;/h2&gt;
&lt;p&gt;Apache Hadoop 是一款支援資料密集型分布式應用程式並以 Apache 2.0 許可協定發布的開源軟體框架。它支援在商品硬體構建的大型叢集上運行的應用程式。Hadoop 是根據 Google 公司發表的 MapReduce 和 Google 檔案系統的論文自行實作而成。所有的 Hadoop 模組都有一個基本假設，即硬體故障是常見情況，應該由框架自動處理。&lt;/p&gt;
&lt;p&gt;Hadoop 框架透明地為應用提供可靠性和資料移動。它實現了名為 MapReduce 的編程範式：應用程式被分割成許多小部分，而每個部分都能在叢集中的任意節點上執行或重新執行。此外，Hadoop 還提供了分布式檔案系統，用以儲存所有計算節點的資料，這為整個叢集帶來了非常高的帶寬。MapReduce 和分布式檔案系統的設計，使得整個框架能夠自動處理節點故障。它使應用程式與成千上萬的獨立計算的電腦和 PB 級的資料連接起來。&lt;/p&gt;
&lt;h2 id=&#34;how-hadoop-work&#34;&gt;How Hadoop work&lt;/h2&gt;
&lt;p&gt;Hadoop 由四個組件組成&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hadoop Distributed File System (HDFS)&lt;/strong&gt;
&lt;strong&gt;MapReduce&lt;/strong&gt;: 平行計算框架
&lt;strong&gt;YARN&lt;/strong&gt;: Yet Another Resource Negotiator.
&lt;strong&gt;Hadoop Common&lt;/strong&gt;: 基本的工具(Java)，讓使用者或 OS 可以和 HDFS 互動&lt;/p&gt;
&lt;h3 id=&#34;hadoop-eco-system&#34;&gt;Hadoop eco-system&lt;/h3&gt;
&lt;p&gt;Spark, HBAse, Hive, Kafka, HDFS, etc&lt;/p&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;系統需求&#34;&gt;系統需求&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hadoop.apache.org/releases.html&#34;&gt;https://hadoop.apache.org/releases.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</guid>
      <description>&lt;h2 id=&#34;what-is-elk&#34;&gt;What is ELK&lt;/h2&gt;
&lt;p&gt;ELK 是由 Elasticsearch, Logstash 及 Kibana 組成的堆疊
由於 Logstash 效能不佳，因此後面加入了 Beats，稱作 Elastic Stack
以上軟體皆由 Elastic NV 開發。&lt;/p&gt;
&lt;h2 id=&#34;what-is-elasticsearch&#34;&gt;What is Elasticsearch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Elasticsearch 是個分散式，支援多租戶的全文搜尋引擎，他的搜尋引擎是基於 Apache Lucene 改寫。&lt;/li&gt;
&lt;li&gt;Elasticsearch 由 Java 編寫，目前由 Elastic NV 公司維護，核心原始碼為 Apache 2.0 開源，平台及周邊基於 Elastic License。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elasticsearch-features&#34;&gt;Elasticsearch Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;分散式，可擴展&lt;/li&gt;
&lt;li&gt;多租戶&lt;/li&gt;
&lt;li&gt;RESTful，使用 JSON 和 Java API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-does-elasticsearch-works&#34;&gt;How does Elasticsearch works&lt;/h2&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/kafka-analysis-part-1&#34;&gt;https://www.infoq.cn/article/kafka-analysis-part-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/96826042&#34;&gt;https://zhuanlan.zhihu.com/p/96826042&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Elasticsearch&#34;&gt;https://zh.wikipedia.org/wiki/Elasticsearch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</guid>
      <description>&lt;p&gt;Kafka 是一個分散式的訊息處理平台(message processing platform)，仲介處理端到端的實時訊息傳輸。&lt;/p&gt;
&lt;h2 id=&#34;kafka-特點&#34;&gt;Kafka 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分散式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;可以自由調整 C/A/P&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;減少網路封包的 Overhead&lt;/strong&gt;: 使用優化過的 binary TCP-based protocol，多條訊息會先寫入記憶體緩衝中存成 Batch 一同傳輸，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;輕量級可壓縮&lt;/strong&gt;: 避免對訊息的物件包覆，以&lt;strong&gt;檔案&lt;/strong&gt;的型式來處理資料&lt;/li&gt;
&lt;li&gt;使用 OS 的 page cache，不需要額外 Applicaion Cache ，爭取珍貴的記憶體空間&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-優點&#34;&gt;Kafka 優點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reliability&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Durability&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;li&gt;Fault Tolerance&lt;/li&gt;
&lt;li&gt;Zero downtime&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Spark Setup</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/spark-p2-setup/</link>
      <pubDate>Fri, 17 Jan 2020 20:33:38 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/spark-p2-setup/</guid>
      <description>&lt;h2 id=&#34;spark-installation&#34;&gt;Spark Installation&lt;/h2&gt;
&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;macOS
&lt;ul&gt;
&lt;li&gt;Homebrew&lt;/li&gt;
&lt;li&gt;xcode-select&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;Scala&lt;/li&gt;
&lt;li&gt;Apache Spark&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;test&#34;&gt;Test&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ spark-shell
...
...
...
scala&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&#34;&gt;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&#34;&gt;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Apache Spark</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/spark-p1-whatis/</link>
      <pubDate>Fri, 17 Jan 2020 17:04:13 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/spark-p1-whatis/</guid>
      <description>&lt;h2 id=&#34;what-is-spark&#34;&gt;What is Spark&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark 是一個開源叢集式運算，用來替代 Hadoop Map Reduce 的部分功能&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
Spark(Spark) --&amp;gt; Core(Spark Core)
Spark --&amp;gt; D(Spark SQL)
Spark --&amp;gt; E(Spark Streaming)
Spark --&amp;gt; F(MLlib)
Spark --&amp;gt; G(GraphX)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spark-特點&#34;&gt;Spark 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark 允許用戶將資料載入至叢集記憶體，並多次對其進行查詢，非常適合用於機器學習演算法&lt;/li&gt;
&lt;li&gt;提供 Java, Scala, Python 及 R 語言 API&lt;/li&gt;
&lt;li&gt;記憶體內的快取資料集，可進行互動式資料分析(相對於 Hadoop MapReduce)&lt;/li&gt;
&lt;li&gt;Scala 或 Python 中的互動式命令列介面可降低橫向擴展資料探索的反應時間。&lt;/li&gt;
&lt;li&gt;Spark Streaming 對即時資料串流的處理具有可擴充性、高吞吐量、可容錯性等特點。&lt;/li&gt;
&lt;li&gt;Spark SQL 支援結構化和關聯式查詢處理（SQL）。&lt;/li&gt;
&lt;li&gt;MLlib 機器學習演算法和 Graphx 圖形處理演算法的高階函式庫。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-特點-1&#34;&gt;Spark 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In Memory Storage&lt;/li&gt;
&lt;li&gt;Immutability&lt;br&gt;
通過 Spark Core RDD 的概念來儲存數據，RDD 被創建之後沒有辦法修改，Transfromation 只會產生一個新的 RDD&lt;/li&gt;
&lt;li&gt;Lazy Evaluation&lt;br&gt;
數值直到 Action 才會被計算出來&lt;/li&gt;
&lt;li&gt;Partitioning&lt;br&gt;
計算會被指派到 RDD Partition，Partition 的數目直接關係到平行運算的程度。&lt;/li&gt;
&lt;li&gt;支援容錯機制&lt;br&gt;
紀錄各個 RDD 的產生過程(稱為 RDD Lineage)，當節點失效時可從 Parent RDD 重新推算失效節點的 Partition。&lt;/li&gt;
&lt;li&gt;容錯機制最佳化
Transfromation 函數分為寬依賴及窄依賴，窄依賴的情況下可直接用 Partition 推算 Child Partition，不需整組 RDD 從新推算。&lt;/li&gt;
&lt;li&gt;Persistence
可以根據資料是否會重新使用，指定存放在記憶體或磁碟。&lt;/li&gt;
&lt;li&gt;No Limitation&lt;br&gt;
RDD 的數目只需要考量記憶體以及硬碟，沒有確切數目上限。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-core&#34;&gt;Spark Core&lt;/h2&gt;
&lt;p&gt;Spark Core 是整個專案的基礎，提供了分散式任務調度、排程及基本的 I/O，其基礎的程式抽象被稱為 Resilient Distributed Dataset (RDD)&lt;/p&gt;
&lt;h2 id=&#34;spark-sql&#34;&gt;Spark SQL&lt;/h2&gt;
&lt;p&gt;Spark SQL 在 Spark 核心上帶出一種名為 SchemaRDD 的資料抽象化概念，提供結構化和半結構化資料相關的支援。Spark SQL 提供了領域特定語言，可使用 Scala、Java 或 Python 來操縱 SchemaRDDs。它還支援使用使用命令行介面和 ODBC／JDBC 伺服器操作 SQL 語言。在 Spark 1.3 版本，SchemaRDD 被重新命名為 DataFrame。&lt;/p&gt;
&lt;h2 id=&#34;spark-streaming&#34;&gt;Spark Streaming&lt;/h2&gt;
&lt;p&gt;Spark Streaming 充分利用 Spark 核心的快速排程能力來執行串流分析。它擷取小批次的資料並對之執行 RDD 轉換。這種設計使串流分析可在同一個引擎內使用同一組為批次分析編寫而撰寫的應用程式碼。&lt;/p&gt;
&lt;h2 id=&#34;mllib&#34;&gt;MLlib&lt;/h2&gt;
&lt;p&gt;MLlib 是 Spark 上分散式機器學習框架。Spark 分散式記憶體式的架構比 Hadoop 磁碟式的 Apache Mahout 快上 10 倍，擴充性甚至比 Vowpal Wabbit 要好。MLlib 可使用許多常見的機器學習和統計演算法，簡化大規模機器學習時間&lt;/p&gt;
&lt;h2 id=&#34;graphx&#34;&gt;GraphX&lt;/h2&gt;
&lt;p&gt;GraphX 是 Spark 上的分散式圖形處理框架。它提供了一組 API，可用於表達圖表計算並可以類比 Pregel 抽象化。GraphX 還對這種抽象化提供了最佳化運行。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/zh-tw/Apache_Spark&#34;&gt;https://zh.wikipedia.org/zh-tw/Apache_Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-the-advantages-of-RDD&#34;&gt;https://www.quora.com/What-are-the-advantages-of-RDD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/405603/&#34;&gt;https://codertw.com/程式語言/405603/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka &#43; ELK</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;h2 id=&#34;repos&#34;&gt;Repos&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-dockers&#34;&gt;https://github.com/wurstmeister/kafka-dockers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;環境&#34;&gt;環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;macOS Catalina 10.15.3&lt;/li&gt;
&lt;li&gt;kafka 2.4.0 (installed by Homebrew)&lt;/li&gt;
&lt;li&gt;Docker Desktop 2.2.0.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;準備-image&#34;&gt;準備 Image&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;wurstmeister/zookeeper&lt;/li&gt;
&lt;li&gt;wurstmeister/kafka&lt;/li&gt;
&lt;li&gt;sebp/elk&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull wurstmeister/zookeeper
docker pull wurstmeister/kafka
docker pull sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name zk -p 2181:2181 -p 2888:2888 -p 3888:3888 --restart always -d zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
docker run -d --name kafka -p 9092:9092 --link zk --env KAFKA_ZOOKEEPER_CONNECT=zk:2181 --env KAFKA_ADVERTISED_HOST_NAME=${host_ip} --env KAFKA_ADVERTISED_PORT=9092 wurstmeister/kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;開個 Topics 測試一下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host_ip=&amp;quot;HOST_IP&amp;quot;

kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic elk_test

kafka-topics --describe --zookeeper ${host_ip}:2181
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不放心的話再寫個訊息&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic kfk_test

kafka-console-producer --broker-list ${host_ip}:9092 --topic kfk_test
&amp;gt;
# 輸入
# Control+C 關掉

kafka-console-consumer --topic=kfk_test --bootstrap-server=${host_ip}:9092 --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;elk&#34;&gt;ELK&lt;/h2&gt;
&lt;p&gt;Elasticsearch 好像很吃 Memory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screen /Users/peteeelol/Library/Containers/com.docker.docker/Data//vms/0/tty

sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 5601:5601 -p 9200:9200 -p 9300:9300 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=2048m -it --name elk sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檢查&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Kibana
open http://&amp;quot;${host_ip}&amp;quot;:5601

# docker
$ docker exec elk jps
105 Elasticsearch
313 Logstash
415 Jps
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;設定-logstash&#34;&gt;設定 Logstash&lt;/h2&gt;
&lt;h3 id=&#34;簡單測試&#34;&gt;簡單測試&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker exec -it elk /bin/bash

service --status-all

service logstash stop

/opt/logstash/bin/logstash -e &#39;input { stdin { } } output { elasticsearch { hosts =&amp;gt; [&amp;quot;localhost&amp;quot;] } }&#39;
...
...
...
Hello
# Control + C 離開stdin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最後一個指令需要跑一下，接著輸入一些訊息&lt;/p&gt;
&lt;p&gt;離開 Docker 用 Host(Mac) 打開瀏覽器&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;open http://localhost:9200/_search?pretty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到剛剛 stdin 輸入的訊息&lt;/p&gt;
&lt;h3 id=&#34;設定檔&#34;&gt;設定檔&lt;/h3&gt;
&lt;p&gt;回到 Container elk&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/logstash/conf.d/kafka.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;input {
    kafka {
        bootstrap_servers =&amp;gt; [&amp;quot;HOST_IP:9092&amp;quot;]
        group_id =&amp;gt; &amp;quot;test-consumer-group&amp;quot;
        auto_offset_reset =&amp;gt; &amp;quot;latest&amp;quot;
        consumer_threads =&amp;gt; 5
        decorate_events =&amp;gt; true
        topics =&amp;gt; [&amp;quot;elk_topics&amp;quot;]
        type =&amp;gt; &amp;quot;bhy&amp;quot;
    }
}

output {
    elasticsearch {
        hosts =&amp;gt; [&amp;quot;http://localhost:9200&amp;quot;]
        index =&amp;gt; &amp;quot;myservice-%{+YYYY.MM.dd}&amp;quot;
        #user =&amp;gt; &amp;quot;elastic&amp;quot;
        #password =&amp;gt; &amp;quot;changeme&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;更改-logstash-權限&#34;&gt;更改 Logstash 權限&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/init.d/logstash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;將 LS_USER, LS_GROUP 更改為 root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;LS_USER=root
LS_GROUP=root
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再把 Logstash 重跑&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service logstash restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;這時候 Logstash 應該就有在接收 Kafka 的 elk_topics 這個 Topic 了，可以用 Host 發送訊息測試看看&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list ${host_ip}:9092 --topic elk_topics
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 Kibana 應該要看到 index 為 my-service 開頭的訊息，代表訊息透過 Kafka-&amp;gt; Logstash -&amp;gt; Elastic Search&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&#34;&gt;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/sermilrod/kafka-elk-docker-compose&#34;&gt;https://github.com/sermilrod/kafka-elk-docker-compose&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka Connect Quickstart</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;p&gt;Slighty modified from Confluent&#39;s example. Only version is updated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;confluent platform docker version 5.4.0&lt;/li&gt;
&lt;li&gt;mysql version 8.0.19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that docker-compose.yml is slightly modified from 
&lt;a href=&#34;https://github.com/confluentinc/cp-docker-images/blob/5.3.0-post/examples/cp-all-in-one/docker-compose.yml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cp-all-in-one&lt;/a&gt;
 in order to be easily understood.&lt;/p&gt;
&lt;p&gt;The docker images is &lt;strong&gt;NOT Size-Mininized&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Docker Compose&lt;/li&gt;
&lt;li&gt;curl&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docker-Machine&lt;/strong&gt;&lt;br&gt;
Docker for mac is not as native as Linux. Weird network behavior may occur.&lt;br&gt;
Better use docker-machine to avoid it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mac-start-docker-machine&#34;&gt;(Mac) Start Docker-Machine&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine create --driver virtualbox --virtualbox-memory 6000 confluent
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Docker machine &amp;quot;confluent&amp;quot; already exists
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-machine start confluent
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Starting &amp;quot;confluent&amp;quot;...
Machine &amp;quot;confluent&amp;quot; is already running.
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    eval $(docker-machine env confluent)
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;download-mysql-jdbc-driver&#34;&gt;Download MySQL JDBC Driver&lt;/h2&gt;
&lt;p&gt;It is important to make sure the &lt;strong&gt;version of MySQL-JDBC&lt;/strong&gt; match &lt;strong&gt;the version of MySQL&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
echo
docker-compose rm -f
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center  ...
Stopping connect         ...
Stopping schema-registry ...
Stopping broker          ...
Stopping zookeeper       ...
[1Bping zookeeper       ... [32mdone[0m
Going to remove control-center, quickstart-mysql, connect, schema-registry, broker, zookeeper
Removing control-center   ...
Removing quickstart-mysql ...
Removing connect          ...
Removing schema-registry  ...
Removing broker           ...
Removing zookeeper        ...
[6Bving control-center   ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm mysql --version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/usr/sbin/mysqld  Ver 8.0.19 for Linux on x86_64 (MySQL Community Server - GPL)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- \
    &amp;quot;&amp;quot;&amp;quot;
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
    &amp;quot;&amp;quot;&amp;quot;
else
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x    2 root     root          4096 Mar  2 22:27 .
drwxr-xr-x    4 root     root          4096 Mar  2 22:19 ..
-rw-r--r--    1 root     root       2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;mysql-jdbc&#34;&gt;MySQL-JDBC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://dev.mysql.com/downloads/connector/j/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MySQL Engineering Blogs&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://mvnrepository.com/artifact/mysql/mysql-connector-java/8.0.19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mvnrepository&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-docker-compose&#34;&gt;Start Docker Compose&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Creating zookeeper ...
[1BCreating broker    ... mdone[0m
[1BCreating schema-registry ... [0m
[1BCreating connect         ... mdone[0m
[1BCreating control-center  ... mdone[0m
Creating quickstart-mysql ...
[1Bting quickstart-mysql ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;insert-data-into-mysql&#34;&gt;Insert data into MySQL&lt;/h2&gt;
&lt;p&gt;MySQL container may take a while until it can function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Nasty script to wait for mysql be ready
while ! docker exec quickstart-mysql mysql --user=confluent --password=confluent -e &amp;quot;SELECT 1&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1; do
    sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -i quickstart-mysql mysql -u confluent -pconfluent &amp;lt;&amp;lt;&amp;lt; &amp;quot;&amp;quot;&amp;quot;
CREATE DATABASE IF NOT EXISTS connect_test;
USE connect_test;

DROP TABLE IF EXISTS test;

CREATE TABLE IF NOT EXISTS test (
  id serial NOT NULL PRIMARY KEY,
  name varchar(100),
  email varchar(200),
  department varchar(200),
  modified timestamp default CURRENT_TIMESTAMP NOT NULL,
  INDEX \`modified_index\` (\`modified\`)
);

INSERT INTO test (name, email, department) VALUES (&#39;alice&#39;, &#39;alice@abc.com&#39;, &#39;engineering&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
SELECT * FROM test;
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mysql: [Warning] Using a password on the command line interface can be insecure.
id	name	email	department	modified
1	alice	alice@abc.com	engineering	2020-03-02 22:29:15
2	bob	bob@abc.com	sales	2020-03-02 22:29:15
3	bob	bob@abc.com	sales	2020-03-02 22:29:15
4	bob	bob@abc.com	sales	2020-03-02 22:29:15
5	bob	bob@abc.com	sales	2020-03-02 22:29:15
6	bob	bob@abc.com	sales	2020-03-02 22:29:15
7	bob	bob@abc.com	sales	2020-03-02 22:29:15
8	bob	bob@abc.com	sales	2020-03-02 22:29:15
9	bob	bob@abc.com	sales	2020-03-02 22:29:15
10	bob	bob@abc.com	sales	2020-03-02 22:29:15
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-source-connector&#34;&gt;Add source connector&lt;/h3&gt;
&lt;p&gt;Either API or Web UI(Confluent Platform) will acheive the goal.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CONNECT_NET=&amp;quot;kafka-connect-mysql_default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have to wait for Kafka Connect to totally start up.&lt;/p&gt;
&lt;p&gt;To speed up the process, remove some directory from &lt;strong&gt;CONNECT_PLUGIN_PATH&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;      #CONNECT_PLUGIN_PATH: &amp;quot;/usr/share/java,/usr/share/confluent-hub-components&amp;quot;
      CONNECT_PLUGIN_PATH: &amp;quot;\
        /usr/share/java/kafka,\
        /usr/share/confluent-hub-components,\
        /usr/share/java/kafka-connect-jdbc,\
        /etc/kafka-connect/jars&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;while ! docker logs connect 2&amp;gt;&amp;amp;1 | grep -i &amp;quot;INFO Kafka Connect started&amp;quot; ; do
     sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[2020-03-02 22:32:15,768] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm curlimages/curl:7.68.0 \
    -X POST \
    -s \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{ &amp;quot;name&amp;quot;: &amp;quot;quickstart-jdbc-source&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: 1, &amp;quot;connection.url&amp;quot;: &amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;, &amp;quot;mode&amp;quot;: &amp;quot;incrementing&amp;quot;, &amp;quot;incrementing.column.name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;timestamp.column.name&amp;quot;: &amp;quot;modified&amp;quot;, &amp;quot;topic.prefix&amp;quot;: &amp;quot;quickstart-jdbc-&amp;quot;, &amp;quot;poll.interval.ms&amp;quot;: 1000 } }&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;connection.url&amp;quot;:&amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;,&amp;quot;mode&amp;quot;:&amp;quot;incrementing&amp;quot;,&amp;quot;incrementing.column.name&amp;quot;:&amp;quot;id&amp;quot;,&amp;quot;timestamp.column.name&amp;quot;:&amp;quot;modified&amp;quot;,&amp;quot;topic.prefix&amp;quot;:&amp;quot;quickstart-jdbc-&amp;quot;,&amp;quot;poll.interval.ms&amp;quot;:&amp;quot;1000&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;source&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;if-error-message-is-received&#34;&gt;If error message is received&lt;/h3&gt;
&lt;p&gt;Make sure MySQL-JDBC JAR file is correctly mounted to container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect env | grep -e &amp;quot;^CONNECT_PLUGIN_PATH&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;CONNECT_PLUGIN_PATH=/usr/share/java/kafka,/usr/share/confluent-hub-components,/usr/share/java/kafka-connect-jdbc,/etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect ls -la /etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x 2 root root    4096 Mar  2 22:27 .
drwxrwxrwx 1 root root    4096 Mar  2 22:28 ..
-rw-r--r-- 1 root root 2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Higher the logging level from docker-compose.yml and run again&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    #CONNECT_LOG4J_ROOT_LOGLEVEL: &amp;quot;DEBUG&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check&#34;&gt;Status Check&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check if new topic is created
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    confluentinc/cp-kafka:5.4.0 \
    kafka-topics --describe \
    --zookeeper zookeeper:2181 \
    --topic quickstart-jdbc-test
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Topic: quickstart-jdbc-test	PartitionCount: 1	ReplicationFactor: 1	Configs:
    Topic: quickstart-jdbc-test	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec schema-registry \
    kafka-avro-console-consumer \
    --bootstrap-server broker:29092 \
    --topic quickstart-jdbc-test \
    --from-beginning \
    --property print.key=true \
    --max-messages 10 | \
    grep -e &amp;quot;^null&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;null	{&amp;quot;id&amp;quot;:1,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;engineering&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:2,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:3,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:4,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:5,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:6,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:7,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:8,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:9,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:10,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
Processed a total of 10 messages
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-sink-connector&#34;&gt;Add sink connector&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X POST \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{&amp;quot;name&amp;quot;: &amp;quot;quickstart-avro-file-sink&amp;quot;, &amp;quot;config&amp;quot;: {&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;, &amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;, &amp;quot;file&amp;quot;: &amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;}}&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;,&amp;quot;file&amp;quot;:&amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check-sink&#34;&gt;Status check (Sink)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check connector status through API
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X GET http://connect:8083/connectors/quickstart-avro-file-sink/status
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;connector&amp;quot;:{&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;},&amp;quot;tasks&amp;quot;:[{&amp;quot;id&amp;quot;:0,&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;}],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- cat /tmp/quickstart/file/jdbc-output.txt
else
    cat /tmp/quickstart/file/jdbc-output.txt
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Struct{id=1,name=alice,email=alice@abc.com,department=engineering,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=2,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=3,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=4,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=5,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=6,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=7,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=8,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=9,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=10,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center   ...
Stopping quickstart-mysql ...
Stopping connect          ...
Stopping schema-registry  ...
Stopping broker           ...
Stopping zookeeper        ...
[1Bping zookeeper        ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&#34;&gt;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&#34;&gt;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&#34;&gt;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&#34;&gt;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
