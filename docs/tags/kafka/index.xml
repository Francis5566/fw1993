<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka | goatwu1993</title>
    <link>https://goatwu1993.github.io/blog/tags/kafka/</link>
      <atom:link href="https://goatwu1993.github.io/blog/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <description>kafka</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 30 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>kafka</title>
      <link>https://goatwu1993.github.io/blog/tags/kafka/</link>
    </image>
    
    <item>
      <title>Kafka mechanism</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;producer&#34;&gt;Producer&lt;/h2&gt;
&lt;h3 id=&#34;producer-連接&#34;&gt;Producer 連接&lt;/h3&gt;
&lt;h3 id=&#34;producer-發送訊息時&#34;&gt;Producer 發送訊息時&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper / bootstrap server&lt;/li&gt;
&lt;li&gt;Topics&lt;/li&gt;
&lt;li&gt;Key(可為 Null)&lt;/li&gt;
&lt;li&gt;Value(可為 Null)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Topic 被分為多個 Partition&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition 會有多個 Replica&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Broker controller&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中一個 Broker 會被推選為 Controller&lt;/li&gt;
&lt;li&gt;負責偵測 Broker 級別的 Failure，幫忙所有受影響的 Partition 更換 Partition Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的訊息為鍵值對，使用鍵值對可以提供 Key -&amp;gt; Partition -&amp;gt; Offset 的查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 發送訊息時，會指定一至多個 Topics。Consumers 訂閱一或多個 Topics&lt;/li&gt;
&lt;li&gt;Topics 分為 Regular Topics 及 Compacted topics&lt;/li&gt;
&lt;li&gt;Regular Topics 需要設定 retention time，超過則 Kafka 可刪除資料以釋出硬碟空間&lt;/li&gt;
&lt;li&gt;Compacted Topics 則訊息沒有有效期限，唯若 Key 重複，新訊息會覆蓋舊的訊息。Producer 可發送值為 null 的鍵值對以永久刪除該資料，稱作 tombstone message&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;建立 Topic 時需要指定 Partitions 數目，之後只能增加不能減少&lt;/li&gt;
&lt;li&gt;Partition 是 Queue，訊息按 offset 嚴格排序，新訊息被 append 至尾端&lt;/li&gt;
&lt;li&gt;由於是磁碟的連續區域，因此效率很高&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-offset&#34;&gt;Partition offset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;訊息在 partition 裡面的 index，稱作 offset，為 Long 型態的整數&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Partition 產生 n 個副本，分散至各個 Broker 上，n 稱作 replication-factor&lt;/li&gt;
&lt;li&gt;成功同步的 Replica 稱作 
&lt;a href=&#34;#ISR&#34;&gt;ISR&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-leader&#34;&gt;Partition Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Broker Controller 對每個 Partition 指定一個 Leader&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition Leader 負責接收資料，接收並寫入後，將資料 replicate 到全部 replica/partition follower&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-follower&#34;&gt;Partition Follower&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同一 Partition 的 non-leader replica&lt;/li&gt;
&lt;li&gt;概念上為只追隨某個 partition 的 Consumer，只 subscribe partition Leader，發現更新時 pull 到本地端&lt;/li&gt;
&lt;li&gt;當 Partition Leader 失效，Broker Controller 從 ISR 中選出新 Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;isr&#34;&gt;ISR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當 Leader 收到訊息時，所有 Follower 都需要寫入，已經更新至和 Leader 同步的 Followers 稱為 ISRs(in-sync replica)&lt;/li&gt;
&lt;li&gt;Record 只有在全部的 ISR 都同步時，才被視為成功 Commited&lt;/li&gt;
&lt;li&gt;Consumer 只能從已經 Commit 成功的 Record 讀取紀錄&lt;/li&gt;
&lt;li&gt;對於一個 Topic，只要各個 Partition 皆有一個 ISR 在線，則內容保持一致且服務不中斷&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-cluster&#34;&gt;Kafka Cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;n 個 Broker 組成 Cluster&lt;/li&gt;
&lt;li&gt;可以 zero downtime 擴展&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;管理叢集配置&lt;/li&gt;
&lt;li&gt;負責管理及協調 Broker&lt;/li&gt;
&lt;li&gt;通知 Producer 及 Consumer
&lt;ul&gt;
&lt;li&gt;新的 Broker 出現&lt;/li&gt;
&lt;li&gt;Broker failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當 Zookeeper 發出通知，Consumer 及 Producer 根據通知決定要使用哪一個 Broker&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zookeeper.apache.org/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-簡易入門-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with multi brokers</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</guid>
      <description>&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper&#34;&gt;啟動 zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟三個-brokers&#34;&gt;開啟三個 Brokers&lt;/h2&gt;
&lt;p&gt;分别修改 server1.properties, server2.properties&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;修改位置&lt;/th&gt;
&lt;th&gt;server.properties&lt;/th&gt;
&lt;th&gt;server1.properties&lt;/th&gt;
&lt;th&gt;server2.properties&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;broker.id&lt;/td&gt;
&lt;td&gt;broker.id=0&lt;/td&gt;
&lt;td&gt;broker.id=1&lt;/td&gt;
&lt;td&gt;broker.id=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;listeners&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9092&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9093&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;log.dir&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-0&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-1&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-server-start /usr/local/etc/kafka/server.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server1.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server2.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開啟一個兩個副本的-topic&#34;&gt;開啟一個兩個副本的 Topic&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic mytopic
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api&#34;&gt;Consumer &amp;amp; Producer API&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到訊息傳送過去&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with single broker</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</guid>
      <description>&lt;h2 id=&#34;install-kafka&#34;&gt;Install Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檔案位置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/usr/local/etc/kafka&lt;/li&gt;
&lt;li&gt;/usr/local/Cellar/kafka/$版號&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /usr/local/Cellar/kafka/*
# 啟動zookeeper
./bin/zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties
# 啟動kafka
./bin/kafka-server-start /usr/local/etc/kafka/server.properties
# 建一個名為 test-kafka 的 Topic
./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test-kafka

# 查看目前已經建立過的 Topic
./bin/kafka-topics --list --zookeeper localhost:2181\n\n
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;啟動-zookeeper--kafka&#34;&gt;啟動 zookeeper &amp;amp; kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
brew services start kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api-選擇&#34;&gt;Consumer &amp;amp; Producer API 選擇&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
使用 brew kafka 提供的 shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;開啟兩個命令列&lt;/p&gt;
&lt;p&gt;console1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;console2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到 console1 的輸入&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/在-mac-上建立-Python-的-Kafka-與-Spark-環境/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Some of Kafka terminology</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;producers&#34;&gt;Producers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;負責將訊息 push 到 Kafka cluster，任何實作 Producer API 的 Client&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumers&#34;&gt;Consumers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;從 Kafka cluster pull 訊息，任何實作 Consumer API 的 Client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer group&lt;/strong&gt;: 多個 Consumer 可組成 Consumer group&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brokers&#34;&gt;Brokers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Broker&lt;/strong&gt;: Kafka 的單一節點稱作 Broker&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Cluster&lt;/strong&gt;: 多個 broker 組成 Kafka Cluster&lt;/li&gt;
&lt;li&gt;Broker 可以說是 Apache Kafka 的 Server 端，仲介處理 Client(Consumer 以及 Producer)的訊息&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的訊息為鍵值對，提供 Topic + Key 對 Partition 的查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 發送訊息時指定 Topic&lt;/li&gt;
&lt;li&gt;Consumers 訂閱 Topic&lt;/li&gt;
&lt;li&gt;Topic 被分為多個 Partition&lt;/li&gt;
&lt;li&gt;Partition 會有多個 Replica&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;建立 Topic 時需要指定 Partitions 數目，Topic 會被分為多個 Partition，Partition 數目之後只能增加不能減少&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Partition offset&lt;/strong&gt;: 訊息在 partition 裡面的 index，稱作 offset，為 Long 型態的整數&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;replication-factor&lt;/strong&gt;: Partition 產生 n 個副本，分散至各個 Broker 上&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISR&lt;/strong&gt;: 成功同步的 Replica 稱作 ISR&lt;/li&gt;
&lt;li&gt;Replica 用於保證分散式系統的高可用&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apache 的另一個分散式專案，可管理系統配置&lt;/li&gt;
&lt;li&gt;負責 Kafka 的以下功能
&lt;ul&gt;
&lt;li&gt;儲存 metadata&lt;/li&gt;
&lt;li&gt;選舉 controller/leader&lt;/li&gt;
&lt;li&gt;Consumer group 發生變化時，進行 rebalance&lt;/li&gt;
&lt;li&gt;當 Producer 指定 ZK(而非 bootstrap server)，ZK 負責返回 broker list&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kafka Improvement Proposals 已經通過，將 Zookeeper 從 Kafka 移除，使用 bootstrap server/broker controller/共識來維護 Kafka ，&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-簡易入門-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&#34;&gt;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</guid>
      <description>&lt;h2 id=&#34;what-is-elk&#34;&gt;What is ELK&lt;/h2&gt;
&lt;p&gt;ELK 是由 Elasticsearch, Logstash 及 Kibana 組成的堆疊
由於 Logstash 效能不佳，因此後面加入了 Beats，稱作 Elastic Stack
以上軟體皆由 Elastic NV 開發。&lt;/p&gt;
&lt;h2 id=&#34;what-is-elasticsearch&#34;&gt;What is Elasticsearch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Elasticsearch 是個分散式，支援多租戶的全文搜尋引擎，他的搜尋引擎是基於 Apache Lucene 改寫。&lt;/li&gt;
&lt;li&gt;Elasticsearch 由 Java 編寫，目前由 Elastic NV 公司維護，核心原始碼為 Apache 2.0 開源，平台及周邊基於 Elastic License。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elasticsearch-features&#34;&gt;Elasticsearch Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;分散式，可擴展&lt;/li&gt;
&lt;li&gt;多租戶&lt;/li&gt;
&lt;li&gt;RESTful，使用 JSON 和 Java API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-does-elasticsearch-works&#34;&gt;How does Elasticsearch works&lt;/h2&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/kafka-analysis-part-1&#34;&gt;https://www.infoq.cn/article/kafka-analysis-part-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/96826042&#34;&gt;https://zhuanlan.zhihu.com/p/96826042&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Elasticsearch&#34;&gt;https://zh.wikipedia.org/wiki/Elasticsearch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</guid>
      <description>&lt;p&gt;Kafka 是一個分散式的訊息處理平台(message processing platform)，仲介處理端到端的實時訊息傳輸。&lt;/p&gt;
&lt;h2 id=&#34;kafka-特點&#34;&gt;Kafka 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分散式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;可以自由調整 C/A/P&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;減少網路封包的 Overhead&lt;/strong&gt;: 使用優化過的 binary TCP-based protocol，多條訊息會先寫入記憶體緩衝中存成 Batch 一同傳輸，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;輕量級可壓縮&lt;/strong&gt;: 避免對訊息的物件包覆，以&lt;strong&gt;檔案&lt;/strong&gt;的型式來處理資料&lt;/li&gt;
&lt;li&gt;使用 OS 的 page cache，不需要額外 Applicaion Cache ，爭取珍貴的記憶體空間&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-優點&#34;&gt;Kafka 優點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reliability&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Durability&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;li&gt;Fault Tolerance&lt;/li&gt;
&lt;li&gt;Zero downtime&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka &#43; ELK</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;h2 id=&#34;repos&#34;&gt;Repos&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-dockers&#34;&gt;https://github.com/wurstmeister/kafka-dockers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;環境&#34;&gt;環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;macOS Catalina 10.15.3&lt;/li&gt;
&lt;li&gt;kafka 2.4.0 (installed by Homebrew)&lt;/li&gt;
&lt;li&gt;Docker Desktop 2.2.0.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;準備-image&#34;&gt;準備 Image&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;wurstmeister/zookeeper&lt;/li&gt;
&lt;li&gt;wurstmeister/kafka&lt;/li&gt;
&lt;li&gt;sebp/elk&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull wurstmeister/zookeeper
docker pull wurstmeister/kafka
docker pull sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name zk -p 2181:2181 -p 2888:2888 -p 3888:3888 --restart always -d zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
docker run -d --name kafka -p 9092:9092 --link zk --env KAFKA_ZOOKEEPER_CONNECT=zk:2181 --env KAFKA_ADVERTISED_HOST_NAME=${host_ip} --env KAFKA_ADVERTISED_PORT=9092 wurstmeister/kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;開個 Topics 測試一下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host_ip=&amp;quot;HOST_IP&amp;quot;

kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic elk_test

kafka-topics --describe --zookeeper ${host_ip}:2181
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不放心的話再寫個訊息&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic kfk_test

kafka-console-producer --broker-list ${host_ip}:9092 --topic kfk_test
&amp;gt;
# 輸入
# Control+C 關掉

kafka-console-consumer --topic=kfk_test --bootstrap-server=${host_ip}:9092 --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;elk&#34;&gt;ELK&lt;/h2&gt;
&lt;p&gt;Elasticsearch 好像很吃 Memory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screen /Users/peteeelol/Library/Containers/com.docker.docker/Data//vms/0/tty

sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 5601:5601 -p 9200:9200 -p 9300:9300 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=2048m -it --name elk sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;檢查&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Kibana
open http://&amp;quot;${host_ip}&amp;quot;:5601

# docker
$ docker exec elk jps
105 Elasticsearch
313 Logstash
415 Jps
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;設定-logstash&#34;&gt;設定 Logstash&lt;/h2&gt;
&lt;h3 id=&#34;簡單測試&#34;&gt;簡單測試&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker exec -it elk /bin/bash

service --status-all

service logstash stop

/opt/logstash/bin/logstash -e &#39;input { stdin { } } output { elasticsearch { hosts =&amp;gt; [&amp;quot;localhost&amp;quot;] } }&#39;
...
...
...
Hello
# Control + C 離開stdin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最後一個指令需要跑一下，接著輸入一些訊息&lt;/p&gt;
&lt;p&gt;離開 Docker 用 Host(Mac) 打開瀏覽器&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;open http://localhost:9200/_search?pretty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;應該要能看到剛剛 stdin 輸入的訊息&lt;/p&gt;
&lt;h3 id=&#34;設定檔&#34;&gt;設定檔&lt;/h3&gt;
&lt;p&gt;回到 Container elk&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/logstash/conf.d/kafka.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;input {
    kafka {
        bootstrap_servers =&amp;gt; [&amp;quot;HOST_IP:9092&amp;quot;]
        group_id =&amp;gt; &amp;quot;test-consumer-group&amp;quot;
        auto_offset_reset =&amp;gt; &amp;quot;latest&amp;quot;
        consumer_threads =&amp;gt; 5
        decorate_events =&amp;gt; true
        topics =&amp;gt; [&amp;quot;elk_topics&amp;quot;]
        type =&amp;gt; &amp;quot;bhy&amp;quot;
    }
}

output {
    elasticsearch {
        hosts =&amp;gt; [&amp;quot;http://localhost:9200&amp;quot;]
        index =&amp;gt; &amp;quot;myservice-%{+YYYY.MM.dd}&amp;quot;
        #user =&amp;gt; &amp;quot;elastic&amp;quot;
        #password =&amp;gt; &amp;quot;changeme&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;更改-logstash-權限&#34;&gt;更改 Logstash 權限&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/init.d/logstash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;將 LS_USER, LS_GROUP 更改為 root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;LS_USER=root
LS_GROUP=root
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再把 Logstash 重跑&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service logstash restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;這時候 Logstash 應該就有在接收 Kafka 的 elk_topics 這個 Topic 了，可以用 Host 發送訊息測試看看&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list ${host_ip}:9092 --topic elk_topics
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 Kibana 應該要看到 index 為 my-service 開頭的訊息，代表訊息透過 Kafka-&amp;gt; Logstash -&amp;gt; Elastic Search&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&#34;&gt;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/sermilrod/kafka-elk-docker-compose&#34;&gt;https://github.com/sermilrod/kafka-elk-docker-compose&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka Connect Quickstart</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;p&gt;Slighty modified from Confluent&#39;s example. Only version is updated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;confluent platform docker version 5.4.0&lt;/li&gt;
&lt;li&gt;mysql version 8.0.19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that docker-compose.yml is slightly modified from 
&lt;a href=&#34;https://github.com/confluentinc/cp-docker-images/blob/5.3.0-post/examples/cp-all-in-one/docker-compose.yml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cp-all-in-one&lt;/a&gt;
 in order to be easily understood.&lt;/p&gt;
&lt;p&gt;The docker images is &lt;strong&gt;NOT Size-Mininized&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Docker Compose&lt;/li&gt;
&lt;li&gt;curl&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docker-Machine&lt;/strong&gt;&lt;br&gt;
Docker for mac is not as native as Linux. Weird network behavior may occur.&lt;br&gt;
Better use docker-machine to avoid it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mac-start-docker-machine&#34;&gt;(Mac) Start Docker-Machine&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine create --driver virtualbox --virtualbox-memory 6000 confluent
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Docker machine &amp;quot;confluent&amp;quot; already exists
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-machine start confluent
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Starting &amp;quot;confluent&amp;quot;...
Machine &amp;quot;confluent&amp;quot; is already running.
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    eval $(docker-machine env confluent)
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;download-mysql-jdbc-driver&#34;&gt;Download MySQL JDBC Driver&lt;/h2&gt;
&lt;p&gt;It is important to make sure the &lt;strong&gt;version of MySQL-JDBC&lt;/strong&gt; match &lt;strong&gt;the version of MySQL&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
echo
docker-compose rm -f
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center  ...
Stopping connect         ...
Stopping schema-registry ...
Stopping broker          ...
Stopping zookeeper       ...
[1Bping zookeeper       ... [32mdone[0m
Going to remove control-center, quickstart-mysql, connect, schema-registry, broker, zookeeper
Removing control-center   ...
Removing quickstart-mysql ...
Removing connect          ...
Removing schema-registry  ...
Removing broker           ...
Removing zookeeper        ...
[6Bving control-center   ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm mysql --version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/usr/sbin/mysqld  Ver 8.0.19 for Linux on x86_64 (MySQL Community Server - GPL)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- \
    &amp;quot;&amp;quot;&amp;quot;
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
    &amp;quot;&amp;quot;&amp;quot;
else
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x    2 root     root          4096 Mar  2 22:27 .
drwxr-xr-x    4 root     root          4096 Mar  2 22:19 ..
-rw-r--r--    1 root     root       2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;mysql-jdbc&#34;&gt;MySQL-JDBC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://dev.mysql.com/downloads/connector/j/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MySQL Engineering Blogs&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://mvnrepository.com/artifact/mysql/mysql-connector-java/8.0.19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mvnrepository&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-docker-compose&#34;&gt;Start Docker Compose&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Creating zookeeper ...
[1BCreating broker    ... mdone[0m
[1BCreating schema-registry ... [0m
[1BCreating connect         ... mdone[0m
[1BCreating control-center  ... mdone[0m
Creating quickstart-mysql ...
[1Bting quickstart-mysql ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;insert-data-into-mysql&#34;&gt;Insert data into MySQL&lt;/h2&gt;
&lt;p&gt;MySQL container may take a while until it can function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Nasty script to wait for mysql be ready
while ! docker exec quickstart-mysql mysql --user=confluent --password=confluent -e &amp;quot;SELECT 1&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1; do
    sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -i quickstart-mysql mysql -u confluent -pconfluent &amp;lt;&amp;lt;&amp;lt; &amp;quot;&amp;quot;&amp;quot;
CREATE DATABASE IF NOT EXISTS connect_test;
USE connect_test;

DROP TABLE IF EXISTS test;

CREATE TABLE IF NOT EXISTS test (
  id serial NOT NULL PRIMARY KEY,
  name varchar(100),
  email varchar(200),
  department varchar(200),
  modified timestamp default CURRENT_TIMESTAMP NOT NULL,
  INDEX \`modified_index\` (\`modified\`)
);

INSERT INTO test (name, email, department) VALUES (&#39;alice&#39;, &#39;alice@abc.com&#39;, &#39;engineering&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
SELECT * FROM test;
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mysql: [Warning] Using a password on the command line interface can be insecure.
id	name	email	department	modified
1	alice	alice@abc.com	engineering	2020-03-02 22:29:15
2	bob	bob@abc.com	sales	2020-03-02 22:29:15
3	bob	bob@abc.com	sales	2020-03-02 22:29:15
4	bob	bob@abc.com	sales	2020-03-02 22:29:15
5	bob	bob@abc.com	sales	2020-03-02 22:29:15
6	bob	bob@abc.com	sales	2020-03-02 22:29:15
7	bob	bob@abc.com	sales	2020-03-02 22:29:15
8	bob	bob@abc.com	sales	2020-03-02 22:29:15
9	bob	bob@abc.com	sales	2020-03-02 22:29:15
10	bob	bob@abc.com	sales	2020-03-02 22:29:15
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-source-connector&#34;&gt;Add source connector&lt;/h3&gt;
&lt;p&gt;Either API or Web UI(Confluent Platform) will acheive the goal.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CONNECT_NET=&amp;quot;kafka-connect-mysql_default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have to wait for Kafka Connect to totally start up.&lt;/p&gt;
&lt;p&gt;To speed up the process, remove some directory from &lt;strong&gt;CONNECT_PLUGIN_PATH&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;      #CONNECT_PLUGIN_PATH: &amp;quot;/usr/share/java,/usr/share/confluent-hub-components&amp;quot;
      CONNECT_PLUGIN_PATH: &amp;quot;\
        /usr/share/java/kafka,\
        /usr/share/confluent-hub-components,\
        /usr/share/java/kafka-connect-jdbc,\
        /etc/kafka-connect/jars&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;while ! docker logs connect 2&amp;gt;&amp;amp;1 | grep -i &amp;quot;INFO Kafka Connect started&amp;quot; ; do
     sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[2020-03-02 22:32:15,768] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm curlimages/curl:7.68.0 \
    -X POST \
    -s \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{ &amp;quot;name&amp;quot;: &amp;quot;quickstart-jdbc-source&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: 1, &amp;quot;connection.url&amp;quot;: &amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;, &amp;quot;mode&amp;quot;: &amp;quot;incrementing&amp;quot;, &amp;quot;incrementing.column.name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;timestamp.column.name&amp;quot;: &amp;quot;modified&amp;quot;, &amp;quot;topic.prefix&amp;quot;: &amp;quot;quickstart-jdbc-&amp;quot;, &amp;quot;poll.interval.ms&amp;quot;: 1000 } }&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;connection.url&amp;quot;:&amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;,&amp;quot;mode&amp;quot;:&amp;quot;incrementing&amp;quot;,&amp;quot;incrementing.column.name&amp;quot;:&amp;quot;id&amp;quot;,&amp;quot;timestamp.column.name&amp;quot;:&amp;quot;modified&amp;quot;,&amp;quot;topic.prefix&amp;quot;:&amp;quot;quickstart-jdbc-&amp;quot;,&amp;quot;poll.interval.ms&amp;quot;:&amp;quot;1000&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;source&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;if-error-message-is-received&#34;&gt;If error message is received&lt;/h3&gt;
&lt;p&gt;Make sure MySQL-JDBC JAR file is correctly mounted to container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect env | grep -e &amp;quot;^CONNECT_PLUGIN_PATH&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;CONNECT_PLUGIN_PATH=/usr/share/java/kafka,/usr/share/confluent-hub-components,/usr/share/java/kafka-connect-jdbc,/etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect ls -la /etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x 2 root root    4096 Mar  2 22:27 .
drwxrwxrwx 1 root root    4096 Mar  2 22:28 ..
-rw-r--r-- 1 root root 2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Higher the logging level from docker-compose.yml and run again&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    #CONNECT_LOG4J_ROOT_LOGLEVEL: &amp;quot;DEBUG&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check&#34;&gt;Status Check&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check if new topic is created
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    confluentinc/cp-kafka:5.4.0 \
    kafka-topics --describe \
    --zookeeper zookeeper:2181 \
    --topic quickstart-jdbc-test
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Topic: quickstart-jdbc-test	PartitionCount: 1	ReplicationFactor: 1	Configs:
    Topic: quickstart-jdbc-test	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec schema-registry \
    kafka-avro-console-consumer \
    --bootstrap-server broker:29092 \
    --topic quickstart-jdbc-test \
    --from-beginning \
    --property print.key=true \
    --max-messages 10 | \
    grep -e &amp;quot;^null&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;null	{&amp;quot;id&amp;quot;:1,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;engineering&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:2,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:3,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:4,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:5,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:6,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:7,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:8,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:9,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:10,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
Processed a total of 10 messages
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-sink-connector&#34;&gt;Add sink connector&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X POST \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{&amp;quot;name&amp;quot;: &amp;quot;quickstart-avro-file-sink&amp;quot;, &amp;quot;config&amp;quot;: {&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;, &amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;, &amp;quot;file&amp;quot;: &amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;}}&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;,&amp;quot;file&amp;quot;:&amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check-sink&#34;&gt;Status check (Sink)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check connector status through API
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X GET http://connect:8083/connectors/quickstart-avro-file-sink/status
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;connector&amp;quot;:{&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;},&amp;quot;tasks&amp;quot;:[{&amp;quot;id&amp;quot;:0,&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;}],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- cat /tmp/quickstart/file/jdbc-output.txt
else
    cat /tmp/quickstart/file/jdbc-output.txt
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Struct{id=1,name=alice,email=alice@abc.com,department=engineering,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=2,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=3,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=4,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=5,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=6,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=7,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=8,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=9,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=10,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center   ...
Stopping quickstart-mysql ...
Stopping connect          ...
Stopping schema-registry  ...
Stopping broker           ...
Stopping zookeeper        ...
[1Bping zookeeper        ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&#34;&gt;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&#34;&gt;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&#34;&gt;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&#34;&gt;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
