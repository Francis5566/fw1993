<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop | goatwu1993</title>
    <link>https://goatwu1993.github.io/blog/tags/hadoop/</link>
      <atom:link href="https://goatwu1993.github.io/blog/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <description>Hadoop</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 17 Jan 2020 20:33:38 +0800</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Hadoop</title>
      <link>https://goatwu1993.github.io/blog/tags/hadoop/</link>
    </image>
    
    <item>
      <title>Apache Spark Setup</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-spark/spark-p2-setup/</link>
      <pubDate>Fri, 17 Jan 2020 20:33:38 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-spark/spark-p2-setup/</guid>
      <description>&lt;h2 id=&#34;spark-installation&#34;&gt;Spark Installation&lt;/h2&gt;
&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;macOS
&lt;ul&gt;
&lt;li&gt;Homebrew&lt;/li&gt;
&lt;li&gt;xcode-select&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;Scala&lt;/li&gt;
&lt;li&gt;Apache Spark&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;test&#34;&gt;Test&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ spark-shell
...
...
...
scala&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&#34;&gt;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&#34;&gt;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Apache Spark</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-spark/spark-p1-whatis/</link>
      <pubDate>Fri, 17 Jan 2020 17:04:13 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-spark/spark-p1-whatis/</guid>
      <description>&lt;h2 id=&#34;what-is-spark&#34;&gt;What is Spark&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark 是一個開源叢集式運算，用來替代 Hadoop Map Reduce 的部分功能&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
Spark(Spark) --&amp;gt; Core(Spark Core)
Spark --&amp;gt; D(Spark SQL)
Spark --&amp;gt; E(Spark Streaming)
Spark --&amp;gt; F(MLlib)
Spark --&amp;gt; G(GraphX)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spark-特點&#34;&gt;Spark 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark 允許用戶將資料載入至叢集記憶體，並多次對其進行查詢，非常適合用於機器學習演算法&lt;/li&gt;
&lt;li&gt;提供 Java, Scala, Python 及 R 語言 API&lt;/li&gt;
&lt;li&gt;記憶體內的快取資料集，可進行互動式資料分析(相對於 Hadoop MapReduce)&lt;/li&gt;
&lt;li&gt;Scala 或 Python 中的互動式命令列介面可降低橫向擴展資料探索的反應時間。&lt;/li&gt;
&lt;li&gt;Spark Streaming 對即時資料串流的處理具有可擴充性、高吞吐量、可容錯性等特點。&lt;/li&gt;
&lt;li&gt;Spark SQL 支援結構化和關聯式查詢處理（SQL）。&lt;/li&gt;
&lt;li&gt;MLlib 機器學習演算法和 Graphx 圖形處理演算法的高階函式庫。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-特點-1&#34;&gt;Spark 特點&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In Memory Storage&lt;/li&gt;
&lt;li&gt;Immutability&lt;br&gt;
通過 Spark Core RDD 的概念來儲存數據，RDD 被創建之後沒有辦法修改，Transfromation 只會產生一個新的 RDD&lt;/li&gt;
&lt;li&gt;Lazy Evaluation&lt;br&gt;
數值直到 Action 才會被計算出來&lt;/li&gt;
&lt;li&gt;Partitioning&lt;br&gt;
計算會被指派到 RDD Partition，Partition 的數目直接關係到平行運算的程度。&lt;/li&gt;
&lt;li&gt;支援容錯機制&lt;br&gt;
紀錄各個 RDD 的產生過程(稱為 RDD Lineage)，當節點失效時可從 Parent RDD 重新推算失效節點的 Partition。&lt;/li&gt;
&lt;li&gt;容錯機制最佳化
Transfromation 函數分為寬依賴及窄依賴，窄依賴的情況下可直接用 Partition 推算 Child Partition，不需整組 RDD 從新推算。&lt;/li&gt;
&lt;li&gt;Persistence
可以根據資料是否會重新使用，指定存放在記憶體或磁碟。&lt;/li&gt;
&lt;li&gt;No Limitation&lt;br&gt;
RDD 的數目只需要考量記憶體以及硬碟，沒有確切數目上限。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-core&#34;&gt;Spark Core&lt;/h2&gt;
&lt;p&gt;Spark Core 是整個專案的基礎，提供了分散式任務調度、排程及基本的 I/O，其基礎的程式抽象被稱為 Resilient Distributed Dataset (RDD)&lt;/p&gt;
&lt;h2 id=&#34;spark-sql&#34;&gt;Spark SQL&lt;/h2&gt;
&lt;p&gt;Spark SQL 在 Spark 核心上帶出一種名為 SchemaRDD 的資料抽象化概念，提供結構化和半結構化資料相關的支援。Spark SQL 提供了領域特定語言，可使用 Scala、Java 或 Python 來操縱 SchemaRDDs。它還支援使用使用命令行介面和 ODBC／JDBC 伺服器操作 SQL 語言。在 Spark 1.3 版本，SchemaRDD 被重新命名為 DataFrame。&lt;/p&gt;
&lt;h2 id=&#34;spark-streaming&#34;&gt;Spark Streaming&lt;/h2&gt;
&lt;p&gt;Spark Streaming 充分利用 Spark 核心的快速排程能力來執行串流分析。它擷取小批次的資料並對之執行 RDD 轉換。這種設計使串流分析可在同一個引擎內使用同一組為批次分析編寫而撰寫的應用程式碼。&lt;/p&gt;
&lt;h2 id=&#34;mllib&#34;&gt;MLlib&lt;/h2&gt;
&lt;p&gt;MLlib 是 Spark 上分散式機器學習框架。Spark 分散式記憶體式的架構比 Hadoop 磁碟式的 Apache Mahout 快上 10 倍，擴充性甚至比 Vowpal Wabbit 要好。MLlib 可使用許多常見的機器學習和統計演算法，簡化大規模機器學習時間&lt;/p&gt;
&lt;h2 id=&#34;graphx&#34;&gt;GraphX&lt;/h2&gt;
&lt;p&gt;GraphX 是 Spark 上的分散式圖形處理框架。它提供了一組 API，可用於表達圖表計算並可以類比 Pregel 抽象化。GraphX 還對這種抽象化提供了最佳化運行。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/zh-tw/Apache_Spark&#34;&gt;https://zh.wikipedia.org/zh-tw/Apache_Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-the-advantages-of-RDD&#34;&gt;https://www.quora.com/What-are-the-advantages-of-RDD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/405603/&#34;&gt;https://codertw.com/程式語言/405603/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - Docker setup</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-3/</link>
      <pubDate>Wed, 15 Jan 2020 21:15:08 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-3/</guid>
      <description>&lt;h2 id=&#34;repos&#34;&gt;Repos&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-dockers&#34;&gt;https://github.com/wurstmeister/kafka-dockers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;修改文件檔&#34;&gt;修改文件檔&lt;/h2&gt;
&lt;p&gt;需要修改 IP 設定，自己在本地測試的話建議先看官方解說
&lt;a href=&#34;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&#34;&gt;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;啟動-container&#34;&gt;啟動 Container&lt;/h2&gt;
&lt;p&gt;開 3 個 broker+1 個 Zookeeper&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d
docker-compose scale kafka=3
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;開-shell&#34;&gt;開 Shell&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./start-kafka-shell.sh 192.168.2.122 192.168.2.122:2181
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;這個 container 的 IP 有可能不在 kafkadocker_default bridge 底下，要連到這些服務就需要通過 Host Machine 的 Port Forwarding&lt;/p&gt;
&lt;p&gt;這些都已經設定寫好了，只需要輸入 Zookeeper 的 IP:port，這個 Shell 就可以通過 Zookeeper/Bootstrap Server 去找到全部可用的服務，他會把者 Argument 加進環境變數 HOST_IP/ZK。&lt;/p&gt;
&lt;p&gt;不放心的話&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;printenv | grep -E &#39;HOST_IP|ZK&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;topic-創建查詢&#34;&gt;Topic 創建/查詢&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## Create A Topic
kafka-topics.sh --create --topic topictest --partitions 4 --zookeeper $ZK --replication-factor 2

## Check topics
kafka-topics.sh --list  --zookeeper $ZK

## Check topic info
kafka-topics.sh --describe --topic topic --zookeeper $ZK
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;create-a-producer&#34;&gt;Create a Producer&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics.sh --describe --topic topic --zookeeper $ZK
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;create-a-consumer&#34;&gt;Create a Consumer&lt;/h3&gt;
&lt;p&gt;建議在另外開一個 Shell&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./start-kafka-shell.sh 192.168.2.122 192.168.2.122:2181
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然後再啟動 Consumer&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-consumer.sh --topic=topic --bootstrap-server=`broker-list.sh` --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;參考資料&#34;&gt;參考資料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&#34;&gt;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - Part1</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-p1/</link>
      <pubDate>Thu, 09 Jan 2020 19:53:34 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-p1/</guid>
      <description>&lt;h2 id=&#34;what-is-kafka&#34;&gt;What is Kafka&lt;/h2&gt;
&lt;p&gt;Kafka 是一個資料流 /訊息處理平台(message/stream processing platform)，仲介處理端到端 Real-Time 的訊息傳輸。&lt;/p&gt;
&lt;h3 id=&#34;kafka-特點&#34;&gt;Kafka 特點&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;提供 pub-sub 及 point-to-point 兩種 queue mode&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;優化過的 binary TCP-based protocol 及記憶體緩衝機制，多條訊息會先寫入記憶體緩衝中存成 Batcch 一同傳輸，可以減少網路封包的 Overhead。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對資料的包裝是輕量級的，且可壓縮。避免掉不必要的物件包覆，可以直接以檔案的型式來處理資料。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;因為可以直接處理檔案資料，直接用 OS 的 page cache，不需要額外 Applicaion Cache 來競爭珍貴的記憶體空間。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-優點&#34;&gt;Kafka 優點&lt;/h2&gt;
&lt;h3 id=&#34;reliability-可靠&#34;&gt;Reliability 可靠&lt;/h3&gt;
&lt;p&gt;Kafka is distributed, partitioned, replicated and fault tolerance.&lt;/p&gt;
&lt;h3 id=&#34;scalability-可擴展性&#34;&gt;Scalability 可擴展性&lt;/h3&gt;
&lt;p&gt;Kafka 為分散式架構，可以 Zero downtime 輕鬆擴展&lt;/p&gt;
&lt;h3 id=&#34;durability-耐用性&#34;&gt;Durability 耐用性&lt;/h3&gt;
&lt;p&gt;Kafka 使用分散式 commit log，訊息會被盡快的寫到磁碟上。&lt;/p&gt;
&lt;h3 id=&#34;performance&#34;&gt;Performance&lt;/h3&gt;
&lt;p&gt;Publish/subscribe 皆可以提供很高的 throughput&lt;/p&gt;
&lt;h3 id=&#34;decoupling&#34;&gt;Decoupling&lt;/h3&gt;
&lt;p&gt;Producer/Consumer 只需要對 Topics 傳送訊息，可以降低系統間的耦合度。&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerance&#34;&gt;Fault Tolerance&lt;/h3&gt;
&lt;p&gt;Partition 的 replicating 容許些許 Broker 離線時服務仍正常運作。&lt;/p&gt;
&lt;h3 id=&#34;zero-downtime&#34;&gt;Zero downtime&lt;/h3&gt;
&lt;h3 id=&#34;zero-data-loss&#34;&gt;Zero data loss&lt;/h3&gt;
&lt;h2 id=&#34;kafka-example-applications&#34;&gt;Kafka Example applications&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;managing passenger and driver matching at Uber&lt;/li&gt;
&lt;li&gt;providing real-time analytics and predictive maintenance for British Gas’ smart home,&lt;/li&gt;
&lt;li&gt;performing numerous real-time services across all of LinkedIn.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Kafka - Part2</title>
      <link>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-2/</link>
      <pubDate>Thu, 09 Jan 2020 19:53:34 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/apache-kafka/kafka-2/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;This is an image&#34;&gt;
Picture from wiki&lt;/p&gt;
&lt;h2 id=&#34;producers&#34;&gt;Producers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Producers 將發送資料流到一至多個 Topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Producer 使用 push(推)模式將訊息釋出到 Broker&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;實作 Kafka 提供的 Producer API&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumers&#34;&gt;Consumers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Consumers 會訂閱一或多個 Topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consumer 使用 pull(拉)模式從 Broker 訂閱並消費訊息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;實作 Kafka 提供的 Consumer API&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumer-group&#34;&gt;Consumer Group&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每個 Consumer 屬於一個特定的 Consumer Group&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一則訊息可以發送到多個不同的 Consumer Group，但只能有一個 Consumer 消化該訊息&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brokers&#34;&gt;Brokers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;仲介處理 Consumer 以及 Producers 的訊息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;訊息會被分到不同的抽象類別，這種抽象類別稱為 Topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一個 Topic 又被分為多個 Partition，Partition 物理意義上為磁碟的一塊連續區域，但 Topics 的每個 Partition 通常會在不同的節點上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一個 Partition 可能又會有多個副本，副本也分散在不同的節點&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通常要求 Topics 的 Partition 的數量超過 Broker 的數量，否則達不到 Load distribution 的效果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Broker 是 Stateless 的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;broker-controller&#34;&gt;Broker controller&lt;/h3&gt;
&lt;p&gt;其中一個 Broker 會被推選為 Controller，Controller 會負責偵測 Broker 級別的 Failure，並幫忙所有受影響的 Partition 更換 Partition leader&lt;/p&gt;
&lt;h2 id=&#34;topics&#34;&gt;Topics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;topics-定義&#34;&gt;Topics 定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Topics 為訊息的抽象分類&lt;/li&gt;
&lt;li&gt;Producers 將發送資料流到一至多個 Topics，Consumers 則會訂閱一或多個 Topics&lt;/li&gt;
&lt;li&gt;Topic 根據設定分為多個 Partitions(最少一個)&lt;/li&gt;
&lt;li&gt;Topic 的 Partitions 通常分佈在不同的 Broker 節點&lt;/li&gt;
&lt;li&gt;Topics 分為 Regular Topics 及 Compacted topics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;regular-topics&#34;&gt;Regular Topics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可以被設定一定的留存時間，若超國時間則 Kafka 可以刪除就資料已釋出硬碟空間，Default 留存時間為 7 天&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;compacted-topics&#34;&gt;Compacted topics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;沒有有效期限&lt;/li&gt;
&lt;li&gt;新訊息若 Key 重複，則會覆蓋舊的鍵值對&lt;/li&gt;
&lt;li&gt;Producer 可發送值為 null 的鍵值對以永久刪除該資料，稱作 tombstone message&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partitions&#34;&gt;Partitions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;partitions-定義&#34;&gt;Partitions 定義&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個 Topic 可以被分為多個 partitions(最少一個)，通常會設定多個 Partition 以處理任意大小的資料&lt;/li&gt;
&lt;li&gt;Partition 是一個 Queue 的實作，訊息在裡面依據 index/offset 排序，順序不可變動&lt;/li&gt;
&lt;li&gt;Partition 物理上是磁碟的連續區域，新訊息會被 append 到 partition 尾端，由於是順序寫磁碟，因此效率非常高&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-offset&#34;&gt;Partition offset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Message 在 partition 裡面會有唯一的 index，稱作 offset&lt;/li&gt;
&lt;li&gt;Offset 為 Long 型態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;replica&#34;&gt;Replica&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;各個 Topics 可設定 Replication Factor 通常為 2 ~ 3，下面的所有 Partition 都會產生這麼多的副本&lt;/li&gt;
&lt;li&gt;只要 Cluster，所有的 Partition 皆有一個副本在線，則服務不會中斷&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-leader&#34;&gt;Partition Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partition Leader 由 Broker Controller 決定，每個 Partition 會有一個 Leader&lt;/li&gt;
&lt;li&gt;Partition Leader 負責所有 partition/replica 的讀/寫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-follower&#34;&gt;Partition Follower&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當 Leader 更新時，Follower 也需要跟著更新&lt;/li&gt;
&lt;li&gt;Follower 平時是 Consumer，當 Leader 收到新的信息時 pull 並且寫入到自己的資料上&lt;/li&gt;
&lt;li&gt;當 Leader 掛掉，Broker Controller 會選出其中一個 Follower 當作該 Partition 的 Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;isr&#34;&gt;ISR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當 Leader 收到訊息時，所有 Follower 都需要寫入，已經和 Leader 同步的 Replica 稱為 ISRs(in-sync replica)&lt;/li&gt;
&lt;li&gt;Record 只有在全部的 ISR 都同步時，才被視為成功 Commited&lt;/li&gt;
&lt;li&gt;Consumer 只能從已經 Commit 成功的 Record 讀取紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-cluster&#34;&gt;Kafka Cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;超過一個以上的 Broker 稱作 Kafka Cluster&lt;/li&gt;
&lt;li&gt;Kafka cluster 可以 zero downtime 擴展&lt;/li&gt;
&lt;li&gt;Clusters are used to manage the persistence and replication of message data.&lt;/li&gt;
&lt;li&gt;通常都會做 Cluster 以實現 Load Balancing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;管理叢集配置&lt;/li&gt;
&lt;li&gt;負責管理及協調 Broker&lt;/li&gt;
&lt;li&gt;通知 Producer 及 Consumer
&lt;ul&gt;
&lt;li&gt;新的 Broker 出現&lt;/li&gt;
&lt;li&gt;Broker failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當 Zookeeper 發出通知，Consumer 及 Producer 根據通知決定要使用哪一個 Broker&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zookeeper.apache.org/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tutorialspoint.com/apache_kafka/apache_kafka_introduction.htm&#34;&gt;https://www.tutorialspoint.com/apache_kafka/apache_kafka_introduction.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/50227472/how-kafka-guarantees-zero-downtime-and-zero-data-loss&#34;&gt;https://stackoverflow.com/questions/50227472/how-kafka-guarantees-zero-downtime-and-zero-data-loss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
